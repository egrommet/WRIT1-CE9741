## Week 7, November 13: Data, part III – Getting/Making Your Own Datasets

### Pre-class reading

- [Scraping The Web](https://github.com/veltman/learninglunches/tree/master/scraping), by Noah Veltman, 2013
- [How the Data Sausage Gets Made](http://source.mozillaopennews.org/en-US/learning/how-sausage-gets-made/), by Jacob Harris, 2013
- [A Visual Explanation of SQL Joins](http://www.codinghorror.com/blog/2007/10/a-visual-explanation-of-sql-joins.html), by Jeff Atwood, 2007

### What we'll cover

- Freedom of Information requests, FOIA Machine, and MuckRock.
- Introduction to web scraping.
- Combining datasets with spreadsheets and database software.

### Post-class assignments

- Using either spreadsheets or database software, combine the Facebook [government requests](../../data/facebook-government-requests.csv) and [users-by-country](../../data/facebook-users-by-country.csv) datasets. Which governments requested the most number of user accounts per Facebook user? Which countries are missing data? Are they important?
- What government agencies might have unpublished data relevant to your long-term project that you could FOIA? Pick one, and write a FOIA letter. (You don't have to send it.)
- Find a website or online databse that might be worth scraping for your long-term project. If you feel comfortable scraping it, do so. If not, write a "pseudocode" program that describes the steps you'd hypothetically take to scrape it.
